
$L_1$ ノルムは微分可能。

微分可能で、きれいな形にすることができる

リッジはLassoと並んで正則化の代表格。

$$\min_{x} \underbrace{\|Ax - b\|^2}_{\text{最小二乗誤差}} + \underbrace{\lambda \|x\|_2^2}_{\text{L2正則化項}}$$


## 正則化とは
「モデルにわざと『制限』を課すことで、未知のデータに対する予測性能（汎化性能）を高める技術」

練習問題の勉強する学生に、難しい制約を付けて応用力を身に着けさせるような仕組み。

### 問題
問題のモデルが複雑すぎると、手元のデータが細かいノイズまで再現しようと学習→過学習

正則化をかけることで、多少のずれはOKとして全体的にシンプルな曲線を描くようになる。

### 正則化の仕組み
$$\text{全体のコスト} = \text{予測の誤差} + \text{正則化項（重みに対するペナルティ）}$$


### 代表的な2つの正則化
これまでの議論に登場した「リッジ」や「ラッソ」がまさにこれに当たります。

① L2正則化（リッジ）
やり方: 重みの「2乗」をペナルティにする。

効果: 重みを全体的にまんべんなく小さくする。

立ち位置: 計算が安定し、急激な予測の変化を抑える「ブレーキ」の役割。

② L1正則化（ラッソ）
やり方: 重みの「絶対値」をペナルティにする。

効果: 不要な変数の重みをピッタリ 0 にする。

立ち位置: 重要な情報だけを抜き出す「フィルター」の役割。


