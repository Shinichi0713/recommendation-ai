# AD-RecSys: Anomaly-Aware AI Recommendation System

**ユーザーの「いつもと違う」を検知し、最適な一歩を先回りして提案するレコメンデーションエンジン。**

## プロジェクト概要

本レポジトリは時系列や画像に異常検知を行い、いつもと違うことからユーザーにレコメンデーションを行うシステム構築を行います。

従来のレコメンドシステムは「過去の嗜好」に依存しますが、本システムはユーザーの行動パターンの「急激な変化（異常）」を検知します。これにより、ユーザーの潜在的なニーズの変化や、緊急性の高い需要を捉えたパーソナライズを実現します。

<img src="image/README/detecting_girl.png" alt="sequential anormaly detection" width="600" style="display: block; margin: 0 auto;">

### 解決する課題

* **嗜好の固定化:** 過去のデータに縛られすぎたレコメンド（フィルターバブル）の解消。
* **状況変化への即応:** 生活環境や興味の急激な変化（例：旅行前、引越し、ライフイベント）を即座に検知。

## 基礎技術

### 異常検知
異常検知に関する詳細です。

- [anormaly_detect_techs/](anormaly_detect_techs/) : 異常検知調査した手法概要
- [anormaly_detect_techs/src](anormaly_detect_techs/src) : 異常検知の調査内容

<details>

<summary>
異常検知の手法群
</summary>

# 画像系の異常検知

## ニューラルネットワーク系異常検知
画像内の異常検知（Visual Anomaly Detection）には、先ほどのオートエンコーダ（AE）以外にも、データの性質や精度に合わせていくつかの代表的なアプローチがあります。

大きく分けて以下の4つのカテゴリーに分類できます。

### 1. 再構成ベース（Reconstruction-based）

「正常を学習し、復元できないものを異常とする」手法です。

* **AE (Autoencoder):** 最も基本的。
* **VAE (Variational Autoencoder):** データの分布を学習するため、AEよりノイズに強く、滑らかな復元が可能。
* **GAN (Generative Adversarial Networks):** 敵対的生成ネットワーク。正常画像を生成する能力が非常に高く、精細な異常検知に向く（例：AnoGAN）。

### 2. 特徴量抽出・統計ベース（Embedding-based）

最新の主流手法です。学習済みのAI（ResNetなど）を使って画像の特徴を数値化し、正常データの分布から外れたものを探します。

* **PaDiM:** 画像をパッチ（小さな領域）に分け、各場所の統計的な「正常分布」を記憶する。位置ずれに強く、計算が比較的速い。
* **PatchCore:** 正常な画像の特徴を「メモリバンク」に保存し、テスト画像と照合する。現在、製造業の検査などで**最高峰の精度**を誇る手法の一つ。
* **Spade:** 画像全体ではなく、局所的な特徴を比較する。

### 3. 自己教師あり学習ベース（Self-supervised-based）

画像に意図的なノイズや加工を加え、それを元に戻す訓練を通して「正常」を深く理解させる手法です。

* **CutPaste:** 画像の一部を切り取って別の場所に貼るという「擬似的な異常」を自ら作り出し、それを当てる練習をさせる。少ないデータでも高精度になりやすい。

### 4. 分離・分類ベース（One-Class Classification）

「正常」を囲う境界線を作る手法です。

* **Deep SVDD:** 正常データが多次元空間上で一つの「点（中心）」に集まるように学習させる。その中心から遠いものを異常と判定する。
* **One-Class SVM:** 古典的ですが、特徴量が整理されている場合には強力。


### 手法の比較まとめ

| 手法 | 得意なこと | 苦手なこと |
| --- | --- | --- |
| **AE / VAE** | 概念がシンプルで実装が容易 | 微細な傷（ボケるため） |
| **PatchCore** | **圧倒的な精度**、少量のデータ | メモリ使用量が多い |
| **CutPaste** | 異物混入の検知 | 形状の歪みや色の変化 |
| **Deep SVDD** | データの中心からの逸脱検知 | 複雑なテクスチャの変化 |

### 使い分けのアドバイス

* **まずは試したい:** `Autoencoder`
* **実用レベルの精度が欲しい:** `PatchCore` や `PaDiM`
* **異常の場所（ヒートマップ）を特定したい:** `PaDiM` や `PatchCore`

もし特定の業界（工場の外観検査、医療画像、防犯カメラなど）での利用を想定されているのであれば、その用途に最適な手法をより詳しく解説できます。


## 非ニューラルネットワーク系

ニューラルネットワーク（ディープラーニング）を使わない手法は、計算負荷が低く、**少量のデータでも動作する**点や、 **「なぜ異常と判定されたか」の根拠が数学的に説明しやすい** （説明責任を果たしやすい）というメリットがあります。

主な手法を4つのアプローチに分けてリストアップします。


### 統計・確率分布ベース

データが特定の確率分布（正規分布など）に従うと仮定し、そこから大きく外れる値を異常とする手法です。

* **ホテリングの  法:**
データが単一の正規分布に従うと仮定します。平均からの距離（マハラノビス距離）を計算し、統計的な閾値を超えたら異常と判定します。
* **マハラノビス・タグチ法 (MT法):**
日本で生まれた手法で、製造業の外観検査などでよく使われます。複数の変数の相関関係を考慮して「正常な状態（単位空間）」を定義し、そこからの外れ度合いを測ります。

### 距離・密度ベース

データ同士の距離や、周囲にどれだけデータが集まっているか（密度）に注目する手法です。

* **k近傍法 (k-Nearest Neighbor, k-NN):**
新しいデータから近い順に  個のデータを探し、その距離の平均が大きければ「周りに仲間がいない＝異常」と判断します。非常にシンプルで直感的です。
* **LOF (Local Outlier Factor):**
単純な距離だけでなく「周囲の密度」を考慮します。データの塊から少し離れた点や、密度の低い場所にポツンとある点を見つけるのが得意です。

### 木構造（アンサンブル）ベース
データを条件分岐で切り分けていく手法です。

* **アイソレーションフォレスト (Isolation Forest):**
データをランダムな条件で切り分けていき、孤立させるまでの回数を数えます。
* **異常値:** 特徴的なので、少ない回数の切り分けですぐに孤立する。
* **正常値:** 集団の中にいるので、孤立させるまでに何度も切り分けが必要。
この「切り分け回数の少なさ」を異常スコアとします。計算が非常に高速です。



### 空間分割・境界ベース

正常データを取り囲む「境界線」を引く手法です。

* **One-Class SVM (Support Vector Machine):**
高次元空間上で正常データを原点からできるだけ遠ざけ、境界線を引きます。その境界線の外側にあるものを異常とみなします。少量のデータでも境界を引きやすいのが特徴です。


### 行列分解

行列分解（Matrix Factorization）を用いた異常検知手法は、特に **「低ランク行列復元（Low-Rank Matrix Recovery）」** という枠組みで非常に強力な力を発揮します。

画像における基本的な考え方は、 **「正常な背景（共通パターン）」は低ランクな行列** で表現でき、 **「異常（動体や欠陥）」はまばらな（Sparse）な行列** で表現できるという性質を利用するものです。

代表的な手法を2つ紹介します。


#### RPCA (Robust Principal Component Analysis)

行列分解を用いた異常検知の中で、最も有名かつエレガントな手法です。

__仕組み__

入力画像行列  を、以下の2つの行列の和に分解します。


* ** (Low-rank):** 低ランク行列。画像全体の共通するパターン（背景や正常な構造）を表します。
* ** (Sparse):** スパース行列。ほとんどの要素が0で、一部だけに値がある行列。これが**「異常（傷、汚れ、侵入者）」**を表します。

__画像検知での使われ方__

監視カメラの映像から「動いている不審者」だけを抽出したり、製品の表面画像から「突発的なキズ」を抽出したりするのに非常に有効です。


#### 非負値行列分解 (NMF: Non-negative Matrix Factorization)

データの要素がすべて正（0以上）であることを利用した手法です。画像データ（輝度値）は負の値をとらないため、非常に相性が良いです。

__仕組み__

画像行列  を、2つの小さな行列 （基底）と （重み）に分解します。


* **:** 正常データに含まれる「部品（パーツ）」のような特徴。
* **:** そのパーツをどれくらい組み合わせて元の画像を構成するか。

__異常検知のやり方__

1. 正常画像だけで  を学習します。
2. 未知の画像  が来たとき、学習済みの  を使って近似します。
3. **近似しきれなかった残差（）**が大きい場所を異常と判定します。


### 行列分解タイプのメリットとデメリット

| 特徴 | メリット | デメリット |
| --- | --- | --- |
| **透明性** | 数学的に分解されるため、結果が明快。 | 線形な関係しか捉えられないことが多い。 |
| **解釈性** |  行列を見れば、異常の形がそのまま現れる。 | 計算コスト（特異値分解など）が高め。 |
| **学習データ** | 正常データが少なくても動作しやすい。 | 複雑なテクスチャの変化に弱い。 |


### Pythonでの簡易実装イメージ（RPCA風）

Pythonの `numpy` を使って、SVD（特異値分解）を利用した簡易的な低ランク近似による異常抽出の考え方を示します。

```python
import numpy as np

# M: 画像をベクトル化して並べた行列
# U, S, Vh: 特異値分解
U, s, Vh = np.linalg.svd(M, full_matrices=False)

# 上位k個の特異値だけ残して「正常（低ランク）」を復元
k = 5
L = U[:, :k] @ np.diag(s[:k]) @ Vh[:k, :]

# 元の画像から「正常」を引き算すると「異常（Sparse）」が残る
Anomaly_Sparse = M - L
```

</details>

## 主な機能

* **Real-time Anomaly Detection**: LSTM/VAEを用いた行動パターンの異常検知。
* **Contextual Recommendation**: 検知された異常スコアに基づき、推薦アルゴリズムの重みを動的に調整。
* **Scalable Architecture**: 大規模な時系列ログを効率的に処理するデータパイプライン。
* **Visualization Dashboard**: 異常スコアとレコメンド精度の推移を可視化。

## デモ・視覚的イメージ

coming soon

## セットアップ手順

### インストール

coming soon

### クイックスタート

coming soon
