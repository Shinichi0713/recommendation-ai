この質問は核心です。
結論から明確に述べます。

> **画像における「基底ベクトル」とは，
> “画像集合に共通して現れる典型的な見た目パターン（空間構造）”です。**

以下では、**抽象論を避けて**、画像として「何に相当するのか」を段階的に説明します。

---

## 1. まず「画像＝ベクトル」を思い出す

### 1.1 1 枚の画像

* サイズ：(H \times W)
* フラット化すると：
  [
  x \in \mathbb{R}^{HW}
  ]

つまり **1 画素 = 1 次元**。

---

### 1.2 複数画像を並べた行列

[
X = [x_1, x_2, \dots, x_N] \in \mathbb{R}^{HW \times N}
]

この行列に対する **基底ベクトル**は：

[
u_k \in \mathbb{R}^{HW}
]

つまり **「1 枚の画像と同じ形をしたベクトル」**です。

---

## 2. 基底ベクトルを「画像として」見たら何か？

これは PCA の固有ベクトルを可視化すると最も分かりやすいです。

### 2.1 PCA の基底 = Eigen-image

各基底 (u_k) を画像に戻すと：

* 明暗のグラデーション
* 大域的な縞模様
* 照明方向
* ぼんやりした形

になります。

**重要：それは“物体”ではありません。**

---

## 3. 具体例で見る

### 例1：照明が変わるだけの画像集合

データ：

* 同じ物体
* 影の濃さだけ違う

基底画像：

1. 平均画像（全体構造）
2. 上から照明が当たる成分
3. 左右の明るさ差

→ **数枚の「ぼんやり画像」だけで再構成可能**

---

### 例2：固定背景＋小異物

基底画像：

1. 背景そのもの
2. わずかな照明ムラ

異物：

* どの基底にも一致しない
* 残差（スパース）に回る

---

## 4. なぜ基底画像は「ぼんやり」しているのか

理由は明確です。

### 4.1 平均化効果

* PCA / 低ランク分解は
* 多数の画像に共通する方向を抽出

→ 局所的・鋭い構造は平均化で消える

---

### 4.2 高周波は共有されにくい

* エッジや欠陥は
* 位置が毎回違う
* 共有されない

→ 基底になれない

---

## 5. RPCANet の場合の「基底」

RPCANet では：

* 明示的な eigen-image は存在しない
* 代わりに：

| 要素       | 役割     |
| -------- | ------ |
| 畳み込みフィルタ | 局所的基底  |
| ステージの反復  | 低ランク制約 |
| しきい値処理   | スパース分離 |

つまり：

> **「よく出る空間パターン」を通すフィルタの集合 = 暗黙的基底**

---

## 6. 背景 vs 異常を「画像」で見ると

| 成分       | 画像として見えるもの    |
| -------- | ------------- |
| 低ランク (L) | ぼんやりした背景・照明構造 |
| スパース (S) | シャープな点・線・欠陥   |

これは実際に RPCA 結果を可視化すると極めて直感的です。

---

## 7. 重要な誤解を避ける

### 誤解：

> 基底 = 物体のパーツ？

**違います。**

* CNN のフィルタとも違う
* テンプレート画像でもない

基底は：

> **「変動の方向」**

です。

---

## 8. 一文で定義するなら

> **画像における基底ベクトルとは，
> 多数の画像に共通する“明るさや形の変化方向”を画像として表したもの**

---

## 次に理解すると決定的に腹落ちする話題

* 「なぜ欠陥は基底になれないのか（位置ずれの効果）」
* 「基底を増やす（rank を上げる）と異常が消える理由」
* 「CNN フィルタと RPCA 基底の決定的違い」
* 「ViT の token embedding は基底か？」

どれを深掘りしますか。
