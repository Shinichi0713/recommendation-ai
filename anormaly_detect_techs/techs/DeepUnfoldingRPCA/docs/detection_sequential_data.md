時系列データに対してPCAを用いた異常検知を行う手法について説明します。

まず、時系列データにおけるPCAの役割は、複数のセンサーや多次元の指標から **「正常時の相関関係（動きのパターン）」** を抽出し、そこから外れた動きを検知することです。

主に以下の2つのアプローチで活用されます。

### 1. 多変量時系列データの相関異常検知

複数のセンサー（例：工場の温度、圧力、振動数など）が同時に動いている場合、PCAはそれらの**変数間の関係性**を学習します。

* **仕組み**: 正常なデータから主成分を求め、「正常な空間（主成分部分空間）」を作ります。
* **異常の定義**: 新しいデータが入力された際、そのデータが「正常な空間」からどれだけはみ出しているかを計算します。
* **指標**: 一般的に**SPE（Q統計量）**や**統計量**が使われます。
* **SPE (Squared Prediction Error)**: PCAで復元できなかった残差。センサー間の相関が崩れたときに跳ね上がります。
* ****: 主成分空間内での変動。相関は保たれているが、値そのものが大きく変動したときに反応します。



### 2. 単変量時系列の「形」の異常検知（スライディングウィンドウ）

センサーが1つしかない場合でも、PCAを使って「波形のパターン」の異常を見つけることができます。

* **仕組み**:
1. 時系列データを一定の長さ（ウィンドウ）で切り出し、それをベクトル（1つのデータ点）として扱います。
2. これをずらしながら大量の「波形ベクトル」を作り、PCAを適用します。


* **効果**: PCAは「よくある波形の形」を学習します。突発的なノイズや、普段とは違う周期の動きが現れると、再構成誤差が大きくなり異常として検知できます。


### 画像処理（RPCANet）との共通点

あなたが先ほどまで実装していた **RPCANet（Deep Unfolding RPCA）** も、実は時系列データに応用可能です。

* **低ランク成分 ($L$):** 季節性や長期的なトレンド、複数の変数が連動する「いつもの動き」。
* **スパース成分 ($S$):** 突発的なスパイクノイズや、短期間のシステム故障、サイバー攻撃などによる「急激な変化」。

画像における「キズ」を  で抽出したのと全く同じ論理で、時系列データの「スパイク」を  として抽出できます。


### 実装時の注意点

PCAを時系列に使う際のハードルは **「非定常性（時間の経過とともにデータの性質が変わること）」** です。

* **対策**: 常に最新のデータでPCAの主成分を更新し続ける「逐次PCA (Incremental PCA)」や、移動窓を用いる手法が一般的です。

## 時系列異常検知
PCA（主成分分析）を用いた時系列異常検知の核となる考え方は、 **「データの『いつもの相関関係』が壊れた瞬間を見つける」** というものです。

具体的にどのようなステップで異常をあぶり出しているのか、順を追って解説します。


### 1. 「正常な世界」のルールを学習する

多変量の時系列データ（例：3つのセンサー）があるとき、正常な状態では変数同士が連動して動いていることが多いです（例：温度が上がれば圧力が上がる）。

PCAは、この連動している方向（**主成分軸**）を見つけ出します。

* **主成分空間**: データが最もよく動く「主要な通り道」。
* **残差空間**: 普段はほとんどデータが存在しない「ノイズ程度の動き」しかない場所。


### 2. 低次元に凝縮して、また戻す（再構成）

ここが検知のポイントです。PCAモデルにデータを通すと、以下の処理が行われます。

1. **圧縮（射影）**: 入力データを、学習した数個の主成分だけで表現します。
2. **復元（再構成）**: その圧縮された情報から、元の多次元データに戻そうと試みます。

このとき、 **「正常なルールに従っているデータ」** は、少ない主成分だけでも元の形をほぼ完璧に復元できます。


### 3. 「復元できなかった差分」を異常とする

もし「いつもと違う動き（異常）」が含まれるデータが入力されると、PCAが学習したルール（主成分軸）から大きく外れた位置にプロットされます。

* **正常なデータ**: 主成分のルールに乗っているので、復元した結果と元の値がほぼ一致する。
* **異常なデータ**: ルールから外れているため、主成分空間に無理やり押し込んで復元しても、**元の値とは似ても似つかないもの**になります。

この **「元の値」と「復元された値」のズレ（再構成誤差）** が、先ほどのコードで計算した「異常スコア」の正体です。


### 直感的なイメージ：すり抜けテスト

これを例えるなら、 **「特定の形の穴（主成分）が開いた板」** のようなものです。

* **正常なデータ**: 穴と同じ形をしているので、板をスッと通り抜けます（再構成誤差が小さい）。
* **異常なデータ**: 形が歪んでいるため、穴に引っかかって通り抜けられません。この「引っかかり」がエラーとして検知されるのです。

### まとめると

PCAは時系列の「値そのもの」だけを見ているのではなく、 **「複数の変数が作り出す空間的なバランス（構造）」** を見ています。

1. **正常時**: A, B, C のバランスが良い  再構成できる  スコア低
2. **異常時**: A だけが勝手な動きをする  バランスが崩れる  再構成できない  **スコア高！**

このようにして、たとえ値が正常範囲内であっても「組み合わせとしておかしい」動きを検知できるのがPCAの強みです。

この「再構成して差分を見る」という考え方は、実はあなたが最初に取り組んでいた **LISTA（深層展開）の （入力 － 低ランク ＝ スパース）** という構造と全く同じ原理に基づいています。

## 実験

三角関数を用いた時系列データの異常検知にPCAの手法を用いて異常検知してみます。
三角関数の波形の特定の場所に異常を埋め込み、PCAにより異常として検出できるかを実装して確認してみました。

結果は以下の通りです。

<img src="image/detection_sequential_data/1767411585493.png" alt="sequential anormaly detection" width="700" style="display: block; margin: 0 auto;">

## 画像の異常検知との違い

結論から言うと、理論的な**アルゴリズム（数式）は全く同じ**ですが、 **「何をデータ点（サンプル）と見なすか」** というデータの扱い方が異なります。

画像（RPCANetなど）で使ったPCAと、時系列データで使ったPCAの違いを比較して整理しましょう。


### 1. 理論は共通：低ランクとスパースの分離

どちらの場合も、PCAがやっていることは **「データの主要な成分（正常/背景）」と「それ以外の成分（異常/ノイズ）」の分離** です。

* **低ランク（主成分）**: データ全体の共通パターン。画像なら「背景の質感」、時系列なら「変数間の相関パターン」。
* **スパース（残差）**: 共通パターンから外れたもの。画像なら「キズ」、時系列なら「スパイクノイズや故障」。


### 2. 「データの並べ方」の違い

ここが最大の違いです。PCAに入力する行列 $X$ をどう作るかが異なります。

#### **画像に用いるPCA（パッチベース）**

画像を小さな「パッチ」に切り刻み、それぞれのパッチを1つのデータ点として並べます。

* **サンプル**: 1枚の画像から切り出された何百ものパッチ。
* **特徴量**: パッチ内の各ピクセル値（16x16ピクセルなら256次元）。
* **捉えるもの**: ピクセル同士の**空間的な相関**（隣り合うピクセルが似た色であることなど）。

#### **時系列に用いるPCA（多変量ベース）**

時刻ごとのセンサー値を1つのデータ点として並べます。

* **サンプル**: 各時刻（1秒後、2秒後…）。
* **特徴量**: 各センサーの値（センサーA、センサーB、センサーC…）。
* **捉えるもの**: センサー同士の**変数間の相関**（Aが上がるとBも上がることなど）。


### 3. 比較表

| 項目 | 画像のPCA (RPCANet) | 時系列のPCA |
| --- | --- | --- |
| **データの単位** | 画像のパッチ（断片） | 特定時刻の全センサー値 |
| **学習する「正常」** | 繰り返される模様・背景の質感 | センサー間の連動ルール |
| **異常（スパース）** | 背景と異なる「キズ・異物」 | 連動ルールを無視した「異常値」 |
| **次元数** | パッチのピクセル数 | センサーの種類数 |


### 4. RPCANetとの関係

あなたが学んだ **RPCANet** は、実は「画像用のPCA」をより高度にしたものです。

通常のPCAは「1層」で一気に分解しますが、RPCANetはそれを**「多層（Deep Unfolding）」**にすることで、複雑なテクスチャの中でもより精密に「正常」と「異常」を分けることができるようになっています。

もし、この時系列PCAをRPCANetのように「多層」にすれば、非常に複雑な周期性を持つ時系列データの異常検知（例：心電図のわずかな乱れや、複雑な電力網の異常）も可能になります。

**「画像も時系列も、結局は『いつも通りのパターン』から外れたものを探している」**という点では、全く同じ手法のバリエーションだと言えます。


## 多層とは

「多層にする」という言葉は、従来のPCA（1回で計算が終わる統計手法）を、 **「何度も繰り返し修正しながら解を導き出すニューラルネットワーク」** のような形に進化させることを意味します。

特にRPCANetなどの「深層展開（Deep Unfolding）」の文脈では、以下の3つのステップで多層化を理解すると分かりやすいです。


### 1. 「一発勝負」から「繰り返しの洗練」へ

通常のPCAは数学的な計算（特異値分解など）を1回行うだけで、背景と異常を分けようとします。しかし、複雑なデータでは1回ではきれいに分かれません。

多層化（深層展開）では、 **「1層 ＝ 1回の修正」** と考えます。

* **1層目**: ざっくりと異常（スパース成分 ）を抜き出す。
* **2層目**: 1層目の残りカスを見て、さらに細かく異常を抜き出す。
* **N層目**: 何度も繰り返すことで、非常に精度の高い分離を実現する。


### 2. 「固定のルール」から「学習するルール」へ

従来のPCAは、「データのばらつきが最大になる方向を探す」という**固定の数式**で動きます。これに対し、多層のRPCANetでは各層のパラメータを学習します。

* **閾値（しきい値）の学習**: 「どこからを異常と見なすか」という基準を、データに合わせてAIが層ごとに微調整します。
* **重みの学習**: データのどの部分に注目して背景を推定すべきかを、ニューラルネットワークの学習（バックプロパゲーション）によって最適化します。


### 3. 非線形な複雑さへの対応

時系列データや画像が「単純な足し算」で構成されていない場合、1層のPCAでは限界があります。

多層にすることで、層の間に「非線形活性化関数（ReLUなど）」や「閾値関数（ソフトしきい値）」を挟み込むことができます。これにより、 **「少しだけ値が跳ね上がったときは正常だが、ある一定を超えて急激に動いたときだけを異常とする」** といった、複雑な判断基準をモデルが持つようになります。


### 時系列データで「多層」にすると何が嬉しいか？

例えば、工場のセンサーデータ（時系列）を多層のRPCANetで分析する場合を考えてみましょう。

1. **浅い層**: データの大きなトレンド（季節変動や昼夜の差）を「正常」として捉える。
2. **深い層**: 装置の摩耗によるわずかな振動の変化や、一瞬の電圧降下など、 **微細で複雑なパターン** を「異常」として正確に分離する。

通常のPCAが「定規で直線を引く」ようなものだとしたら、多層化は「熟練の職人が何度も見直して、わずかな違和感を見つけ出す」ようなイメージです。

### まとめ

* **1層（PCA）**: 数学的な一発計算。単純な異常には強いが、複雑なパターンには弱い。
* **多層（RPCANet）**: アルゴリズムを何層にも重ねてAIが学習。**「繰り返しの修正」によって、微小で複雑な異常を見つける力が飛躍的に高まる。**

あなたが画像で行ったRPCANetの学習は、まさにこの「繰り返しの修正ルール」をAIに覚えさせていたことになります。時系列でも、この多層の枠組みを使うことで、より高度な予兆検知が可能になります。



