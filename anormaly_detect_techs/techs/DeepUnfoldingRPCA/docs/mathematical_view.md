数式の観点から見ると、多層化（深層展開）とは、 **「最適化問題を解くための反復計算（繰り返し）を、そのままニューラルネットワークの層として読み替える」** という非常にスマートな手法です。

PCAをより強力にした「RPCA（Robust PCA）」を例に、1層の計算と多層化（RPCANet）の違いを数式で紐解きます。


### 1. 基礎となる最適化問題

私たちがやりたいのは、観測データ $M$ を、「低ランクな背景 $L$」と「スパースな異常 $S$」に分けることです。これは以下の数式を最小化する問題（RPCA）として定義されます。

$$
\min_{L, S} \frac{1}{2} \|M - L - S\|_F^2 + \lambda \|S\|_1 + \text{rank}(L)
$$

- 第1項：再現誤差（$M$ が $L+S$ で正しく表せているか）
- 第2項：$S$ をまばら（スパース）にする制約
- 第3項：$L$ を低ランク（いつも通りのパターン）にする制約

### 2. 反復アルゴリズム（ISTA）の数式

この問題を解くための古典的な手法に、 **ISTA（Iterative Shrinkage-Thresholding Algorithm）** という反復アルゴリズムがあります。数式は以下のようになります。

$$
S_{k+1} = \text{soft\_threshold}(S_k + W(M - L - S_k), \theta)
$$

ここで：

- $W$ は更新の方向を決める行列（ステップサイズを含む）
- $\theta$ は異常を切り分ける「しきい値」
- $\text{soft\_threshold}$ は、小さい値をゼロに切り捨てる関数です。

**通常のPCAや古典的RPCA**では、この計算を手動で決めた固定の  と  で、収束するまで何十回、何百回と繰り返します。


### 3. 深層展開（Deep Unfolding）による多層化

ここが「多層化」の本質です。上記の反復式を **「1つの層」** と見なします。

$k$ 回目の繰り返しを第 $k$ 層とし、数式を以下のようにネットワーク化します。

$$
S^{(k)} = \sigma(S^{(k-1)} + W_k(M - L^{(k-1)} - S^{(k-1)}), \theta_k)
$$

#### 何が変わるのか？（数式的メリット）

1. パラメータの学習化 ($W_k, \theta_k$):
古典的な手法では $W$ や $\theta$ は全ステップで共通かつ固定値ですが、RPCANetでは層ごとに異なる値をデータから学習します。
* 浅い層（$k=1, 2$）：大きな異常をざっくり捉えるための大きなしきい値 $\theta_1$。
* 深い層（$k=N$）：微細な異常を拾い上げるための精密なしきい値 $\theta_N$。


2. **少ない層数で高精度:**
固定パラメータの古典的手法では100回繰り返さないと解けない問題も、層ごとにパラメータを最適化することで、わずか**5〜10層（5〜10回の計算）**で極めて正確な異常分離が可能になります。


### 整理

数式の観点で見ると、多層化とは以下の変化を指します。

* **1層（PCA/古典的手法）**: 数式を1回（あるいは固定のルールで繰り返し）解くだけ。
* **多層（RPCANet）**: 数式の1反復を1層に割り当て、**「どう計算すれば最も速く、正確に異常を見つけられるか」という数式自体の係数をAIに最適化させる**構造。

この「数式をネットワークの形に展開する」という考え方が、あなたが画像で使ったLISTAやRPCANetの正体です。


## 教師あり VS 教師なし
**「どのようにISTA（またはRPCA）の数式をニューラルネットワークに落とし込むか」** という設計次第で、**教師あり**・**教師なし**の両方が可能です。

ここが深層展開（Deep Unfolding）の非常に面白いところです。


### 1. 教師あり学習（Supervised）の場合

あなたが NEU-Seg のコードで見た `SoftLoULoss(out_T, labels)` を使うパターンです。

* **必要なもの**: 入力画像と、セットになる**正解マスク（ラベル）**。
* **学習の仕組み**:  ネットワークが出した異常成分 $S$ と、人間が作ったラベルを比較して、「ラベル通りに $S$ を出せるように $W$ と $\theta$ を調整せよ」と命令します。
* **メリット**: 特定のキズ（ひび割れ、汚れなど）を狙い撃ちして検知する精度が極めて高くなります。


### 2. 教師なし学習（Unsupervised / Self-Supervised）の場合

「異常とは何か」というラベルを与えずに学習するパターンです。

* **必要なもの**: 入力画像のみ（できれば正常画像が多い方が望ましい）。
* **学習の仕組み**: 「再構成誤差（$M - (L+S)$）」を最小化するように学習します。
* モデルには「入力 $M$ を、低ランクな $L$ とスパースな $S$ に分解せよ。ただし、足したらちゃんと元の $M$ に戻るようにせよ」というルールだけを与えます。
* 数学的な RPCA の目的関数そのものを損失関数（Loss）として使います。


* **メリット**: ラベルを作る手間が不要で、 **「見たことがない未知の異常」** でも、「低ランク（いつものパターン）ではないもの」として  に分離できるようになります。


### 3. なぜ深層展開なら「教師なし」でも賢くなるのか？

通常のニューラルネットワーク（CNNなど）は、ラベルがないと何を学習していいか分からなくなります。しかし、RPCANet（ISTAの深層展開）は **「数式という土台」** があります。

* ラベルがなくても、「スパース成分 $S$ はなるべく 0 に近く（まばらに）する」という数学的な制約（L1ノルム）を Loss に入れることができます。
* これにより、AIはラベルなしでも **「普段の背景（L）と、たまに現れるトゲトゲしたノイズ（S）を分けるコツ」** を自ら学習していけます。


### まとめ

* **最高精度を目指すなら**: 教師あり（ラベル必要）。
* **汎用性と低コストを目指すなら**: 教師なし（ラベル不要）。

最近のトレンドでは、「正常画像だけ」を使って教師なし学習を行い、異常な画像が入ってきたときに $S$ が大きく反応するように $W, \theta$ をチューニングする手法が、産業界（工場の外観検査など）では特によく使われます。

## 再構成誤差
 **再構成誤差（Reconstruction Error）** とは、一言で言えば **「元のデータと、モデルが作り直したデータの間のズレ（間違い）」** のことです。

異常検知の世界では、この「ズレ」をそのまま **「異常さの度合い（スコア）」** として利用します。

### 1. 「再構成」のプロセス

まず、モデル（PCAやRPCANetなど）が何をしているかを図解すると分かりやすいです。

1. **圧縮（エンコード）**: 複雑な入力データから「重要な特徴（正常なパターン）」だけを抜き出します。
2. **復元（デコード/再構成）**: その抜き出した「正常なルール」だけを使って、元のデータをもう一度描き直します。

これを **「再構成」** と呼びます。


### 2. なぜ「誤差」が異常検知になるのか？

モデルは学習を通じて、**「正常なデータ（いつものパターン）」を効率よく描き直す方法**をマスターします。

* **正常なデータが入ってきた場合**:
モデルは描き方を知っているので、ほぼ元通りに復元できます。
 **再構成誤差が小さい**
* **異常なデータ（見たことがないキズやノイズ）が入ってきた場合**:
モデルは「正常な描き方」しか知りません。異常な部分はモデルにとって「意味不明なノイズ」なので、描き直す際に無視されたり、無理やり正常っぽく修正されたりします。
 その結果、元のデータと描き直したデータの間に大きな差が生まれます。
 **再構成誤差が大きい（＝ここが異常だ！）**


### 3. 数式での定義

最も一般的には、 **「差の2乗（MSE: Mean Squared Error）」** が使われます。

$$
\text{Error} = \| M - (L + S) \|^2
$$

または

$$
\text{Error} = \| \text{Input} - \text{Reconstruction} \|^2
$$

* $M$: 元の観測データ
* $L+S$: モデルが「こうあるべきだ」と再現したデータ

### 4. 直感的な例え：似顔絵

* **正常（家族の顔）**: あなたは家族の顔をよく知っています（学習済み）。目をつぶって描いても、だいたい似た顔が描けます。実物と見比べても、差（誤差）はほとんどありません。
* **異常（宇宙人の顔）**: あなたは宇宙人の描き方を知りません。宇宙人の写真を見せられて「これを描き直して」と言われても、人間の顔のパーツ（正常のルール）で描こうとするため、実物とは全く違う絵になります。この **「実物の宇宙人」と「あなたが描いた絵」のひどい差** が、再構成誤差です。


### まとめ

再構成誤差とは、 **「モデルがどれだけそのデータを『理解（再現）』できなかったか」** を示す指標です。

* **理解できた（誤差小）** ＝「いつものデータ（正常）」
* **理解できなかった（誤差大）** ＝「見たことがないデータ（異常）」

