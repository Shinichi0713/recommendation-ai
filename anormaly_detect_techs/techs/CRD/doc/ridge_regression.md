CRD（Collaborative Representation-based Detector）で、ターゲット画素を再現するための重み係数  を導き出すために使われている数学的なアルゴリズム（解法）は、一般的に **「リッジ回帰（Ridge Regression）」** または **「正則化付き最小二乗法」** と呼ばれます。

SRD（スパース表現）が反復計算を必要とする複雑なアルゴリズムを使うのに対し、CRDはこのリッジ回帰の性質を利用することで、非常にシンプルかつ高速に解を求めることができます。


### 1. アルゴリズムの正体：リッジ回帰（Ridge Regression）

CRDの目的関数は以下の通りです。

$$\min_{\alpha} \|y - D\alpha\|_2^2 + \lambda \|\alpha\|_2^2$$

この式は、以下の2つの要素を同時に最小化しようとしています。

* **第1項（再構成誤差）**: 辞書 $D$ と重み $\alpha$ で、ターゲット $y$ をどれだけ正確に再現できるか。
* **第2項（ 正則化）**: 重み $\alpha$ の値が極端に大きくならないように抑え込み、周囲の画素全員に「協調的」に役割を分散させる。

この問題は **「クローズドフォーム（解析解）」** を持っており、ループ計算（反復法）をせずに行列演算一発で答えが出ます。


### 2. 数学的な解：正規方程式（Normal Equation）

CRDの重み $\alpha$ を求める具体的な数式（アルゴリズムの核心）は以下のようになります。

$$\alpha = (D^T D + \lambda I)^{-1} D^T y$$

* $D^T D$: 辞書（背景画素群）の中の自己相関行列。
* $\lambda I$: 対角要素に微小な値を足すことで、逆行列の計算を安定させる（正則化）。
* $(...)^{-1}$: 逆行列の計算。ここがアルゴリズムのメインステップです。


### 3. なぜ「アルゴリズム」として優秀なのか

CRDが異常検知において「アルゴリズム的に」優れている理由は、 **「一度の行列計算で終わる」** という点に集約されます。

1. **計算の決定性**: SRDのように「収束するまで繰り返す」必要がないため、どんな画像を入力しても計算時間が一定で、リアルタイムシステムに組み込みやすい。
2. **グローバルな最適解**: リッジ回帰は凸最適化問題であるため、常に唯一の「最もバランスの良い重み」を瞬時に見つけることができます。
3. **効率的な行列の実装**: 現代のCPU/GPUは行列演算（特に逆行列や積）が極めて得意なため、プログラムの実装効率が非常に高いです。


### 4. まとめ：SRDのアルゴリズムとの比較

| 手法 | 使われるアルゴリズム名 | 特徴 |
| --- | --- | --- |
| **SRD** | **ISTA, FISTA, OMP** | スパース性を追求する。反復計算が必要で遅い。 |
| **CRD** | **リッジ回帰（正規方程式）** | 協調性を追求する。**行列演算のみで速い。** |

**補足：**
もしデータがハイパースペクトル画像のように非常に高次元な場合、このアルゴリズムは **「核リッジ回帰（Kernel Ridge Regression）」** へと拡張されることもあります。これにより、非線形な背景の関係性も捉えられるようになります。

## アルゴリズム

CRD（Collaborative Representation-based Detector）のアルゴリズムについて、さらに踏み込んだ**「行列演算の効率化」**と**「なぜこの計算が異常を見つけるのか」**の直感的な理解について解説します。

---

### 1. アルゴリズムの数学的プロセス

CRDが各画素で行っている計算は、以下の3ステップに分解できます。

1. **プロジェクション行列（投影行列）の作成**:
背景辞書 $D$ から、$P = (D^T D + \lambda I)^{-1} D^T$ という行列を計算します。これは「背景らしい成分を抽出するためのフィルター」のようなものです。
2. **重みの推定**:
$\alpha = P y$ によって、ターゲット画素 $y$ を再現するために「どの背景画素をどれだけ使うか」という重みを一瞬で決定します。
3. **再構成と残差（異常スコア）算出**:

$\text{Score} = \|y - D\alpha\|_2^2$
背景にあるものだけで自分を再現（$D\alpha$）してみて、どうしても再現できなかった「はみ出し分」を異常として出力します。


### 2. なぜ一画素ずつ計算すると遅いのか？

先ほどのコード例では `for` ループで一画素ずつ処理していましたが、実用上は**「行列のバッチ処理」**を行います。

* **課題**: 全画素に対して個別に逆行列 $(D^T D + \lambda I)^{-1}$ を計算するのは計算機にとって負担です。
* **解決策**:
* **積分画像（Integral Image）の活用**: 窓内の統計量を高速に計算する手法。
* **行列の並列化**: 近年の実装では、GPUを使用して画像内の複数の領域を同時に行列演算にかけることで、高解像度な画像でもリアルタイム（30fps以上）での検知を可能にしています。



---

### 3. CRDと「マハラノビス距離（RX）」の関係

ここが非常に面白いポイントなのですが、**CRDは「局所的なマハラノビス距離」の変形**と見なすことができます。

* **RX Detector**: 画像全体（あるいは大きな窓）の平均と共分散を使う。
* **CRD**: ターゲットのすぐ隣の画素たちを「標本」として、その場で即席の共分散構造（$D^T D$）を作り、そこからの外れ値を測る。

つまり、CRDは**「究極にパーソナライズされた（その場所専用の）異常検知」**を、リッジ回帰というアルゴリズムで実現しているのです。

---

### 4. まとめ：CRDを使いこなすためのヒント

もしCRDを実務で使うなら、以下の「アルゴリズムの癖」を覚えておくと役立ちます。

* **λ（ラムダ）の役割**:
 $\lambda$ を大きくすると、周囲の画素に「もっと平均的に、みんなで協力しろ」と強制します。ノイズが多い画像では $\lambda$ を大きくすると判定が安定します。
* **窓サイズの決定**:
背景の模様が「繰り返し」を持っている場合、その繰り返し（周期）よりも少し大きな窓を設定するのが、アルゴリズムが背景を正しく理解するためのコツです。

---

### 次に何を知りたいですか？

CRDの理論が整理できたところで、次は以下のようなトピックが考えられます：

1. **多次元データへの応用**: ハイパースペクトル画像や、カラー画像（RGB）でのベクトル演算としてのCRD。
2. **さらなる高速化**: 行列演算をスキップして近似的に解く方法。
3. **他の手法との比較**: あなたがこれまでに学んだ「RPCA」や「Deep RX」と、この「CRD」をどう組み合わせるのが最強か。



多次元データ（カラー画像、ハイパースペクトル画像、あるいは動画の時空間データなど）に CRD を応用する場合、各画素は単なる「数値（スカラー）」ではなく、複数の成分を持つ**「ベクトル」**として扱われます。

この場合、アルゴリズムは**「ベクトルの集合としての背景辞書を使って、ターゲットベクトルを再現する」**という多変量解析の形になります。

---

### 1. 多次元 CRD の数学的枠組み

カラー画像（RGB）を例にすると、各画素  は 3次元のベクトル  です。

#### ① 背景辞書の構造

ターゲット画素の周囲から抽出した  個の背景画素を並べて、辞書行列  を作ります。

* 辞書  のサイズ： 
* : データの次元数（RGBなら3、ハイパースペクトルなら数百）
* : 背景窓に含まれる画素数



#### ② リッジ回帰による重み推定

ターゲットベクトル  を再現するための重みベクトル  （ 次元）を求めます。



ここで重要なのは、** が  の行列になる**点です。これは「背景画素同士の類似度」を表しており、これに正則化  を加えることで、特定の画素に依存しすぎない「協調的」な再現が可能になります。

---

### 2. 高次元データにおける「異常」の捉え方

多次元データで CRD を使うと、単なる明るさの違いだけでなく、**「色の組み合わせ（相関）の不自然さ」**を検知できるようになります。

* **スペクトルの一致**:
ハイパースペクトルデータの場合、特定の波長だけが明るいのではなく、全波長のパターン（スペクトル形状）が周囲と違うものを「異常」として鋭く捉えます。
* **空間・波長結合**:
周囲の画素たちが持つスペクトルの「バリエーション」の中に、ターゲットのスペクトルが含まれているかを計算します。

---

### 3. 実装上の工夫：カーネル CRD (KCRD)

次元数  が非常に大きい（ハイパースペクトル画像など）場合や、背景と異常の関係が単純な足し算（線形）で表せない場合、**「カーネル法」**を導入した **KCRD** が使われます。

* **仕組み**: データを高次元の空間に写像してから CRD を行います。
* **メリット**:
計算式の中に  （内積）が含まれているため、**カーネルトリック**を用いることで、明示的に高次元計算をすることなく、複雑な非線形背景からの逸脱を検知できます。

---

### 4. Python によるベクトル版 CRD の実装イメージ

RGB画像を想定した、多次元対応の計算ロジックは以下のようになります。

```python
import numpy as np

def multivariate_crd_score(target_vec, dictionary_matrix, lamda=0.01):
    """
    target_vec: [d, 1] - ターゲット画素のベクトル
    dictionary_matrix (D): [d, n] - 周囲の背景画素ベクトルを並べたもの
    """
    d, n = dictionary_matrix.shape
    
    # 1. 重みアルファの計算 (正規方程式)
    # D.T @ D は [n, n] 行列
    DtD = np.dot(dictionary_matrix.T, dictionary_matrix)
    alpha = np.linalg.solve(DtD + lamda * np.eye(n), np.dot(dictionary_matrix.T, target_vec))
    
    # 2. ターゲットの再構成
    y_hat = np.dot(dictionary_matrix, alpha)
    
    # 3. 再構成誤差（マハラノビス距離に近い指標）
    score = np.linalg.norm(target_vec - y_hat)
    
    return score

```

---

### 5. まとめ：多次元 CRD の強み

多次元化することで、CRD は**「テクスチャ（空間）」と「色（波長）」を同時に考慮した、極めて精度の高いフィルター**へと進化します。

* **応用例**:
* **衛星画像**: 森の中に隠れた人工物（スペクトル異常）の発見。
* **精密基板検査**: 配線の色が周囲の平均からわずかにズレている箇所の特定。
* **動画解析**: 背景の動き（時間軸を含めた多次元）と異なる動きをする物体の検知。



この多次元 CRD の考え方は、以前お話しした **Deep RX**（CNN の特徴マップ＝多次元ベクトルを RX で処理する）とも非常に近い親和性があります。



