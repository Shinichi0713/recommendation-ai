CRD（Collaborative Representation-based Detector）で、ターゲット画素を再現するための重み係数  を導き出すために使われている数学的なアルゴリズム（解法）は、一般的に **「リッジ回帰（Ridge Regression）」** または **「正則化付き最小二乗法」** と呼ばれます。

SRD（スパース表現）が反復計算を必要とする複雑なアルゴリズムを使うのに対し、CRDはこのリッジ回帰の性質を利用することで、非常にシンプルかつ高速に解を求めることができます。


### 1. アルゴリズムの正体：リッジ回帰（Ridge Regression）

CRDの目的関数は以下の通りです。

$$\min_{\alpha} \|y - D\alpha\|_2^2 + \lambda \|\alpha\|_2^2$$

この式は、以下の2つの要素を同時に最小化しようとしています。

* **第1項（再構成誤差）**: 辞書 $D$ と重み $\alpha$ で、ターゲット $y$ をどれだけ正確に再現できるか。
* **第2項（ 正則化）**: 重み $\alpha$ の値が極端に大きくならないように抑え込み、周囲の画素全員に「協調的」に役割を分散させる。

この問題は **「クローズドフォーム（解析解）」** を持っており、ループ計算（反復法）をせずに行列演算一発で答えが出ます。


### 2. 数学的な解：正規方程式（Normal Equation）

CRDの重み $\alpha$ を求める具体的な数式（アルゴリズムの核心）は以下のようになります。

$$\alpha = (D^T D + \lambda I)^{-1} D^T y$$

* $D^T D$: 辞書（背景画素群）の中の自己相関行列。
* $\lambda I$: 対角要素に微小な値を足すことで、逆行列の計算を安定させる（正則化）。
* $(...)^{-1}$: 逆行列の計算。ここがアルゴリズムのメインステップです。


### 3. なぜ「アルゴリズム」として優秀なのか

CRDが異常検知において「アルゴリズム的に」優れている理由は、 **「一度の行列計算で終わる」** という点に集約されます。

1. **計算の決定性**: SRDのように「収束するまで繰り返す」必要がないため、どんな画像を入力しても計算時間が一定で、リアルタイムシステムに組み込みやすい。
2. **グローバルな最適解**: リッジ回帰は凸最適化問題であるため、常に唯一の「最もバランスの良い重み」を瞬時に見つけることができます。
3. **効率的な行列の実装**: 現代のCPU/GPUは行列演算（特に逆行列や積）が極めて得意なため、プログラムの実装効率が非常に高いです。


### 4. まとめ：SRDのアルゴリズムとの比較

| 手法 | 使われるアルゴリズム名 | 特徴 |
| --- | --- | --- |
| **SRD** | **ISTA, FISTA, OMP** | スパース性を追求する。反復計算が必要で遅い。 |
| **CRD** | **リッジ回帰（正規方程式）** | 協調性を追求する。**行列演算のみで速い。** |

**補足：**
もしデータがハイパースペクトル画像のように非常に高次元な場合、このアルゴリズムは **「核リッジ回帰（Kernel Ridge Regression）」** へと拡張されることもあります。これにより、非線形な背景の関係性も捉えられるようになります。

## アルゴリズム

CRD（Collaborative Representation-based Detector）のアルゴリズムについて、さらに踏み込んだ**「行列演算の効率化」**と**「なぜこの計算が異常を見つけるのか」**の直感的な理解について解説します。

---

### 1. アルゴリズムの数学的プロセス

CRDが各画素で行っている計算は、以下の3ステップに分解できます。

1. **プロジェクション行列（投影行列）の作成**:
背景辞書 $D$ から、$P = (D^T D + \lambda I)^{-1} D^T$ という行列を計算します。これは「背景らしい成分を抽出するためのフィルター」のようなものです。
2. **重みの推定**:
$\alpha = P y$ によって、ターゲット画素 $y$ を再現するために「どの背景画素をどれだけ使うか」という重みを一瞬で決定します。
3. **再構成と残差（異常スコア）算出**:

$\text{Score} = \|y - D\alpha\|_2^2$
背景にあるものだけで自分を再現（$D\alpha$）してみて、どうしても再現できなかった「はみ出し分」を異常として出力します。


### 2. なぜ一画素ずつ計算すると遅いのか？

先ほどのコード例では `for` ループで一画素ずつ処理していましたが、実用上は**「行列のバッチ処理」**を行います。

* **課題**: 全画素に対して個別に逆行列 $(D^T D + \lambda I)^{-1}$ を計算するのは計算機にとって負担です。
* **解決策**:
* **積分画像（Integral Image）の活用**: 窓内の統計量を高速に計算する手法。
* **行列の並列化**: 近年の実装では、GPUを使用して画像内の複数の領域を同時に行列演算にかけることで、高解像度な画像でもリアルタイム（30fps以上）での検知を可能にしています。



---

### 3. CRDと「マハラノビス距離（RX）」の関係

ここが非常に面白いポイントなのですが、**CRDは「局所的なマハラノビス距離」の変形**と見なすことができます。

* **RX Detector**: 画像全体（あるいは大きな窓）の平均と共分散を使う。
* **CRD**: ターゲットのすぐ隣の画素たちを「標本」として、その場で即席の共分散構造（$D^T D$）を作り、そこからの外れ値を測る。

つまり、CRDは**「究極にパーソナライズされた（その場所専用の）異常検知」**を、リッジ回帰というアルゴリズムで実現しているのです。

---

### 4. まとめ：CRDを使いこなすためのヒント

もしCRDを実務で使うなら、以下の「アルゴリズムの癖」を覚えておくと役立ちます。

* **λ（ラムダ）の役割**:
 $\lambda$ を大きくすると、周囲の画素に「もっと平均的に、みんなで協力しろ」と強制します。ノイズが多い画像では $\lambda$ を大きくすると判定が安定します。
* **窓サイズの決定**:
背景の模様が「繰り返し」を持っている場合、その繰り返し（周期）よりも少し大きな窓を設定するのが、アルゴリズムが背景を正しく理解するためのコツです。

---

### 次に何を知りたいですか？

CRDの理論が整理できたところで、次は以下のようなトピックが考えられます：

1. **多次元データへの応用**: ハイパースペクトル画像や、カラー画像（RGB）でのベクトル演算としてのCRD。
2. **さらなる高速化**: 行列演算をスキップして近似的に解く方法。
3. **他の手法との比較**: あなたがこれまでに学んだ「RPCA」や「Deep RX」と、この「CRD」をどう組み合わせるのが最強か。

