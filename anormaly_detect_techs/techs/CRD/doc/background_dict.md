CRD（Collaborative Representation-based Detector）において、**背景辞書  を構築するプロセス**は、検出精度を左右する最も重要なステップです。

CRDでは、画像全体で共通の辞書を持つのではなく、**注目している画素（ターゲット）ごとに、その周囲から動的に辞書  を作成**します。

---

### 1. 二重窓（Dual Window）アルゴリズムによる抽出

辞書 $D$ を求めるには、ターゲット画素を中心とした2つのサイズの異なる窓（ウィンドウ）を設定します。

1. **外側の窓（Outer Window / Background Window）**:

背景のサンプルを収集する範囲です。サイズを $W_{out} \times W_{out}$ とします。
2. **内側の窓（Inner Window / Guard Window）**:
ターゲット画素とその極めて近い周囲を含む範囲です。サイズを $W_{in} \times W_{in}$ とします。

**辞書  の作り方：**
外側の窓に含まれる画素のうち、**内側の窓に含まれない画素だけ**を全て抜き出し、それらを列ベクトルとして並べたものが辞書  になります。

---

### 2. なぜ「内側の窓（ガード窓）」が必要なのか？

辞書  を作る際に、ターゲットのすぐ隣（内側の窓）を除外するのには明確な理由があります。

* **異常の汚染を防ぐ**: もしターゲットが異常（例えば小さなキズ）だった場合、そのキズは数ピクセルの広がりを持っていることが多いです。ガード窓がないと、辞書  の中に「異常な画素」が混入してしまいます。
* **再現の禁止**: 異常な画素が辞書に含まれると、アルゴリズムは「異常を異常自身で再現」できてしまい、再構成誤差が小さくなって異常を見逃してしまいます。

---

### 3. データ形状（行列）への変換

多次元データ（RGBやハイパースペクトル）の場合、辞書  は以下の手順で数学的な行列に変換されます。

1. **画素のベクトル化**: 各画素（RGBなら3次元）をベクトル  とします。
2. **行列化**: 選ばれた  個の背景画素ベクトルを横に並べます。

$$D = [v_1, v_2, \dots, v_n]$$

* 行列サイズ： $[d \times n]$ （$d$: 次数, $n$: 背景画素の数）



---

### 4. 実装における具体的な手順（Pythonイメージ）

プログラムで辞書  を抽出する際のロジックは以下の通りです。

```python
# ターゲット座標 (y, x) を中心とした処理
# 1. 外側の窓を切り出す
outer_region = image[y-r_out : y+r_out+1, x-r_out : x+r_out+1]

# 2. マスクを作成してガード窓部分を「偽」にする
mask = np.ones((win_out, win_out), dtype=bool)
# 中心部の (win_in x win_in) を除外
start = (win_out - win_in) // 2
mask[start : start+win_in, start : start+win_in] = False

# 3. マスクを適用して辞書 D を作成
# 背景画素だけを取り出し、(次元数, 画素数) の形に変形
D = outer_region[mask].reshape(-1, channels).T 

```

---

### 5. 辞書  のサイズを決める指針

* **（外枠）**: 背景の「模様（テクスチャ）」が1ユニット収まる程度の大きさが理想です。小さすぎると背景のバリエーションを学習できず、大きすぎると計算が重くなります（通常 9〜15 程度）。
* **（内枠）**: 検出したい異常（キズや異物）の想定サイズより一回り大きく設定します。

### まとめ

CRDの辞書  は、**「ターゲットのすぐ近くだけど、ターゲット自身（異常）は含まない、純粋なお隣さんたちの集合」**です。




CRD（Collaborative Representation-based Detector）における辞書 **** は、一言でいうと**「ターゲットの周囲にある『正常な背景サンプル』を詰め込んだ行列」**です。

具体的にどのような数値の集まりなのか、データの構造をステップバイステップで説明します。

---

### 1. データの構成要素（1画素＝1つのベクトル）

まず、画像の種類によって1画素が持つデータの次元が変わります。

* **グレースケール画像の場合**: 1画素は単なる数値（例：`128`）です。
* **RGBカラー画像の場合**: 1画素は3つの数値のセット（例：`[255, 0, 0]`）です。
* **ハイパースペクトル画像の場合**: 1画素は数百の波長成分（例：`[0.1, 0.2, ..., 0.05]`）を持つ長いベクトルです。

この1画素分のデータの塊を、数学的に **「列ベクトル」** として扱います。

---

### 2. 行列  の具体的な中身

辞書  は、二重窓の外側の枠（背景領域）から抽出された複数の画素ベクトルを**横に並べたもの**です。

例えば、**カラー画像（RGB）**で、背景領域から **100個** の画素を抽出したとすると、辞書  は以下のような行列になります。

* **行（縦方向）**: 各チャンネル（赤・緑・青）の輝度値。
* **列（横方向）**: 抽出された各地点の「背景サンプル」。

---

### 3.  が表現しているもの

この行列  は、その場所における**「正常な色のバリエーション（部分空間）」**を定義しています。

* **もし背景が単色なら**:  の各列はほぼ同じ値になり、辞書は非常に単純な「色の塊」を表します。
* **もし背景にグラデーションや模様があるなら**:  には「少し明るい画素」「少し暗い画素」「色が混ざった画素」など、その場所で起こりうる色の変化がすべてデータとして含まれます。

---

### 4. 数値の具体例（イメージ）

あなたが今、緑色の布の上にある赤い糸（異常）を検出しようとしているとします。

* **ターゲット  （中心）**: `[200, 20, 20]` （赤い糸の画素ベクトル）
* **辞書  （周囲の緑の布）**:
* 画素1: `[30, 180, 40]`
* 画素2: `[32, 185, 38]`
* 画素3: `[28, 175, 42]`
* ...（これが100個並ぶ）



このとき、CRDのアルゴリズムは**「辞書  にある『緑色のベクトル群』をどう足し引きしても、ターゲット  の『赤いベクトル』は作れない（再現誤差が大きい）！」**と判断し、そこを異常として検出します。

---

### まとめ

* **データの正体**: 背景領域から抜き出した画素ベクトルの集合体（行列）。
* **サイズ**: `(データの次元数) × (背景画素の数)`。
* **役割**: 「ここ（局所領域）での正常とは何か？」を示すための**生データの見本帳**。

この「生データの見本帳（）」に対して、ターゲットがどれだけ馴染んでいるかを計算するのがCRDの処理です。



## 背景辞書とは


CRD（Collaborative Representation-based Detector）における背景辞書 $D$ は、画像全体から作るのではなく、 **「今、注目している画素のすぐ周り」から、計算のたびに動的に切り出して作成** されます。

具体的にどのようにデータが収集され、行列として構成されるのかを解説します。


### 1. 二重窓（Dual Window）による抽出

辞書 $D$ を定義するために、ターゲット画素（異常かどうか判定したい点）を中心に、2つのサイズの異なる窓を設定します。

1. **外側の窓（Background Window）**: 背景のサンプルを集めるための大きな枠。
2. **内側の窓（Guard Window）**: ターゲット画素が持つ「異常成分」が背景サンプルに混ざらないようにするための「ガード（空白地帯）」です。

**辞書  $D$ になるデータ**:
「外側の窓」の中に含まれる画素のうち、「内側の窓」の範囲に **含まれない** 


### 2. 行列  の構造

抽出された各画素は、多次元ベクトルとして扱われます。これらを横に並べて一つの大きな行列（辞書）を作ります。

* **1つの画素**: バンド数（RGBなら3、ハイパースペクトルなら ）の次元を持つ列ベクトル 。
* **辞書 $D$**:  個の背景画素を並べた行列。

$$D = [v_1, v_2, \dots, v_n]$$

* **サイズ**: $(バンド数 \times 背景画素数)$



### 3. 数学的な意味：部分空間の定義

この辞書 $D$ を求める作業は、数学的には **「その局所領域における『正常な色のバリエーション』が作る空間（部分空間）」** を定義していることになります。

* 背景がグラデーションしていれば、辞書 $D$ には「少し明るい画素」と「少し暗い画素」の両方が含まれます。
* CRDのアルゴリズムは、この辞書  にある「正常サンプル」を混ぜ合わせることで、ターゲットを再現しようと試みます。


### 4. 具体的なステップ（実装の裏側）

1. **スライディング**: 画像の全画素に対して、窓を1ピクセルずつずらしながら走査します。
2. **サンプリング**: 各地点で、マスク処理によって背景画素のインデックスを特定し、その値を抜き出します。
3. **正規化（オプション）**: 計算の安定性を高めるため、各ベクトルから平均を引いたり、ノルムで割ったりすることもあります。

### 5. 辞書 $D$ の質を決めるパラメータ

辞書をどう「求める」かは、以下の2つの設定次第で変わります。

* **外窓サイズ ($W_{out}$)**:
大きくするほど辞書の語彙（サンプル数）が増えますが、遠くの無関係な画素まで混ざるリスクがあります。
* **内窓サイズ ($W_{in}$)**:
「異常」の想定サイズより少し大きくします。これが小さすぎると、異常の一部が辞書  に紛れ込んでしまい、異常を「正常な背景の一部」として再現できてしまう（＝検出漏れ）の原因になります。


### まとめ

CRDの辞書 $D$ は、**「ターゲットのすぐ近所に住んでいる、信頼できる正常な隣人たちのカタログ」**です。これを動的に作り続けることで、場所ごとに背景が違う複雑な画像でも、精度の高い異常検知が可能になります。


## 背景辞書は使いまわさない

結論から申し上げますと、理論上は **「使うことは可能」** ですが、実用上は **「その場所（局所領域）に限定して使うのが最も効果的」** です。

背景辞書を使い回すかどうかについては、背景の性質によって3つの戦略に分かれます。


### 1. 「使い回さない」のがCRDの本来の強み（局所辞書）

CRDの最大の特徴は、ピクセルごとに辞書 $D$ を作り直すことにあります。

* **理由**: 画像の左端と右端では、照明の当たり方、影の落ち方、テクスチャの歪みが微妙に異なります。
* **メリット**: そのピクセルの「すぐ隣」だけを辞書にすることで、場所による変化（非定常性）を完璧に無視して、そのスポットでの違和感だけを抽出できます。


### 2. 「近傍で使い回す」戦略（セミ・ローカル辞書）

計算速度を稼ぐために、ある程度の範囲で辞書を共有する手法もあります。

* **やり方**: 画像を例えば  ピクセルのブロックに分割し、そのブロック内の全ピクセルに対して、ブロック中心付近で作成した共通の辞書 $D$ を適用します。
* **メリット**: 行列  の計算やその逆行列（または分解）をブロックごとに1回行うだけで済むため、計算速度が劇的に向上します。
* **リスク**: ブロックの境界で「背景モデルのズレ」が生じ、スコアマップに格子状のノイズが出る可能性があります。


### 3. 「画像全体で使い回す」戦略（グローバル辞書）

これはもはやCRDというよりは、最初にお話しした **SRD（スパース表現）** や **Dictionary Learning** に近い考え方になります。

* **やり方**: 正常な画像全体から代表的なパッチを大量に集め、一つの巨大な「マスター辞書」を作っておきます。
* **メリット**: 全ピクセルで全く同じ辞書を使うため、計算の共通化がしやすく、未知の画像に対しても学習済みの辞書を適用できます。
* **デメリット**: 局所的な細かい変化（わずかなグラデーションなど）を「異常」と誤検知しやすくなります。


### まとめ：いつ使い回すべきか？

| 戦略 | 辞書の範囲 | 向き不向き |
| --- | --- | --- |
| **完全局所 (基本)** | 1ピクセルごと | **精度重視。** 背景が複雑な場合に最適。 |
| **ブロック共有** | 数〜数十ピクセル | **速度重視。** 背景が比較的均一な場合に有効。 |
| **グローバル共有** | 画像全体 | **広域の統計特性**を見たい場合。局所性は失われる。 |

### 実装のアドバイス

もし計算速度が遅くて困っている場合は、1ピクセルずつずらすのではなく、 **「ストライド（歩幅）」** を設けるのが一般的です。例えば、3ピクセルおきに辞書を更新し、その間のピクセルは共通の辞書で計算するだけでも、計算量は  に削減されます。



非常にお鋭いご指摘です。実務でCRD（または二重窓アルゴリズム）を使う際、最も懸念されるのがこの**「背景辞書の汚染（Dictionary Contamination）」**です。

結論から言うと、**「多少の混入は計算アルゴリズムが吸収してくれるが、頻度やサイズが大きいと検出漏れ（見逃し）の原因になる」**というのが現実です。

なぜ問題ないのか、あるいはどう対策すべきなのか、3つのポイントで解説します。

---

### 1. なぜ「多少の混入」なら耐えられるのか？

CRDが採用している**「協調表現（L2正則化/リッジ回帰）」**というアルゴリズムが、ここで生きてきます。

* **多数決の原理**: 背景辞書  には通常、数百個の画素が含まれます。そのうち数個だけが異常（異物）だったとしても、圧倒的多数の「正常な画素」が背景モデルを支配します。
* **重みの分散**: CRDは特定の画素だけに頼らず、辞書全員に重みを分散させようとします。異常な画素が1つ混ざっていても、それが全体の再現に与える影響は小さく抑えられます。
* **再構成の失敗**: ターゲットが「大きな異常」で、辞書に「小さな異常の一部」が混ざっている場合でも、辞書内の少量の異常成分だけではターゲット全体を再現しきれず、結果として再構成誤差（異常スコア）は十分に大きく出ます。

---

### 2. 「問題になる」のはどんな時か？

以下のようなケースでは、辞書への混入が致命的な**「自己消去（Self-ghosting）」**を引き起こします。

* **異常が巨大な場合**: 外側の窓の大部分を異常が占めてしまうと、アルゴリズムは「これがこの場所の正常な背景だ」と勘違いしてしまいます。
* **異常が密集している場合**: 1つの異常の隣に別の異常がある場合、隣の異常が背景辞書に入り込み、ターゲットの異常を「協力して」再現してしまいます。

---

### 3. 実務的な回避策

「異常が辞書に入る」ことを前提として、現場では以下のような工夫を組み合わせています。

#### ① ガード窓（Inner Window）を適切に広げる

最も基本的な対策です。異常のサイズに対してガード窓が小さすぎると、異常の「縁（ふち）」の部分が必ず背景辞書に載ってしまいます。ガード窓は**「想定される最大の異常がすっぽり収まるサイズ」**にするのが鉄則です。

#### ② 辞書のロバスト化（反復的CRD）

一度CRDを計算し、異常スコアが高かった画素を**辞書から動的に除外**して、もう一度計算し直すという手法です。「怪しいやつは背景として認めない」というフィルタリングです。

#### ③ 疎なサンプリング

背景窓の画素を「全部」使うのではなく、ランダムに、あるいは間隔を空けてピックアップします。これにより、小さな異常が辞書全体に占める「汚染率」を統計的に下げることができます。

#### ④ 複数窓の併用

サイズの異なる窓で複数回計算し、それらを統合します。小さな異常は小さな窓で、大きな異常は大きな窓で捉えることで、汚染の影響を分散させます。

---

### まとめ

「異常が辞書に入ること」自体は避けられませんが、CRDは**「背景の多数派が形成するルール」**を抽出する手法であるため、汚染率が低ければ（例えば辞書の10%以下など）検出性能は維持されます。

もし、検出したい異常が「非常に大きい」あるいは「たくさん密集している」ようなケースを想定されていますか？その場合は、CRDの前に**グローバルな背景推定（RPCAなど）**を噛ませるのが定石になります。

次は、そういった「密集した異常」に対する具体的なパイプラインの組み方について深掘りしてみますか？