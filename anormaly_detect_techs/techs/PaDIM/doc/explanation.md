**PaDiM (Patch Distribution Modeling)** は、2020年に発表された画像異常検知の手法で、あなたがこれまでに学んできた **Deep RX の概念を「位置（パッチ）ごと」に緻密化したもの**だと考えると非常に理解しやすいです。

MVTec AD などのベンチマークで非常に高い精度を叩き出し、かつ「追加の学習（重みの更新）が不要」という実用性の高さから、現在の産業界でも広く使われています。


### 1. PaDiM の核心的なアイデア

Deep RX では画像全体、あるいは特徴マップ全体で「一つの統計量（平均と共分散）」を計算していましたが、PaDiM はこう考えます。

> **「画像の『左上』にある正常パターンと、『真ん中』にある正常パターンは違うはずだ」**

例えば、ボトルの画像であれば：

* **中央部**: ガラスの滑らかな質感が正常。
* **端の部分**: 背景との境界線（エッジ）があるのが正常。

PaDiM は、特徴マップの各グリッド位置（i, j）ごとに、個別の多変量ガウス分布（平均 $\mu_{ij}$ と共分散 $\Sigma_{ij}$）を保持します。


### 2. 処理の手順

#### ① 特徴抽出（パッチ埋め込み）

学習済みの CNN（ResNetやWide-ResNetなど）に画像を通します。異なる層（Layer 1, 2, 3）から特徴マップを取り出し、それらを連結して、各ピクセル位置における「リッチな特徴ベクトル」を作ります。

#### ② 位置ごとの統計学習（正常モデルの構築）

1. 正常な画像を100枚ほど用意します。
2. 全ての画像において、座標 $(0, 0)$ にある特徴ベクトルだけを集めて $\mu_{0,0}$ と $\Sigma_{0,0}$ を計算します。
3. これを全座標（例：$56 \times 56$ 箇所）に対して行います。
* これにより、 **「この場所における正常な見え方のバリエーション」** を完全に記憶します。



#### ③ 異常検知（推論）

テスト画像が来たら、各座標 $(i, j)$ の特徴ベクトルに対し、その座標専用の分布 $(\mu_{ij}, \Sigma_{ij})$ を使ってマハラノビス距離（RXスコア）を計算します。

* これにより、画像全体で一律に判断するよりも、はるかに精密に「その場所としての異常」を特定できます。


### 3. PaDiM のメリット

* **位置情報の活用**: 画像内の構造的な特徴（「ここはロゴがあるはず」「ここは角のはず」）を理解しているため、位置ずれや構造的な欠陥に強いです。
* **学習が不要（計算のみ）**: ニューラルネットワークの重みを更新する「訓練」が必要ありません。正常画像を通して統計値を計算（行列演算）するだけでモデルが完成します。
* **解像度が高い**: 特徴マップをそのまま使うため、異常箇所をピクセル単位のヒートマップとして非常に綺麗に出力できます。

---

### 4. Deep RX との決定的な違い

| 比較項目 | Deep RX (全体) | PaDiM (位置ごと) |
| --- | --- | --- |
| **分布の数** | 画像全体で **1つ** | グリッド位置ごとに **数千個** |
| **得意な異常** | 異物混入、明らかな変色 | 位置依存の欠陥、構造のわずかな崩れ |
| **メモリ消費** | 非常に少ない | 全位置の共分散行列を持つためやや多い |

---

### まとめ

PaDiM は、**「CNNが持つ強力な目」**に**「場所ごとのマハラノビス距離（RX）」**を組み合わせた、非常に理にかなった進化形です。

もしあなたが以前の Deep RX のコードを拡張するなら、`detector.train` の部分で `features` を一箇所にまとめず、`[h, w]` の各座標ごとに `mean` と `cov` を計算して保存する形に作り変えるだけで、PaDiM のコアエンジンが完成します。

次は、PaDiM の弱点である「メモリ消費量」を克服した、さらなる進化形 **PatchCore** についても興味はありますか？（これは「分布」ではなく「データの塊」を記憶する手法です）