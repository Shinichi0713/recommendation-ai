
本日は背景辞書を使った異常検知法のうち、分けた背景辞書をさらにクラスタリングすることで、CRDの持つ課題を解決した手法について説明します。

## 背景
背景をいくつかの「種類（クラスター）」に分けて管理する方法です。

作り方: 画像全体を K-means などでクラスタリングし、「芝生」「コンクリート」「影」といったグループごとの辞書（または平均ベクトル）を作成します。

__特徴:__

- ターゲット画素がどのクラスターに属するかを判定し、対応する辞書だけを使って計算します。
- LRBに近い考え方ですが、近傍を毎回探すのではなく、あらかじめ分類しておくため高速です。
- 得意なケース: 異なる素材が混在する風景写真や、複数の部品が並ぶ工業製品の検査。


## 従来課題

クラスターベース辞書は、主に **「計算コスト（速度）」** 、  **「背景の多層性（複雑な混ざり具合）」** という、CRDやLRBが抱える実用上の限界を突破するために考案されました。

具体的には、以下の3つの大きな課題を解決しようとしています。


### 1. 「毎回探す・毎回解く」という計算の重さ

CRDやLRBの最大の弱点は、全ピクセルに対して「窓を切り出し、行列の逆行列を解く」という重い処理を繰り返すことです。

* **解決策**: 画像全体をあらかじめいくつかのクラスター（例えば「草地」「道路」「影」）に色やテクスチャで分類しておきます。
* **メリット**: 各ピクセルで計算を行う際、ゼロから辞書を作るのではなく、 **「自分はクラスターAに属するから、クラスターA専用の学習済み辞書を使う」** という選択をするだけで済みます。これにより、処理速度が飛躍的に向上します。

### 2. 「混ざりすぎた背景」による精度の低下

CRDのような局所窓方式では、ターゲットが「草地」と「コンクリート」の境界にある場合、辞書には両方の性質が混ざってしまいます。

* **解決策**: クラスターベースでは、空間的な位置に関わらず、 **「統計的に似ているもの」** だけで辞書を構成します。
* **メリット**: 境界線の上にあるピクセルでも、「草地クラスター」の辞書を使って草地としての整合性をチェックできるため、複数の素材が入り混じる複雑なシーン（都市部の空撮や、部品が密集した基板など）で、背景の「ボケ」を防ぎ、異常を鋭く分離できます。

### 3. 「異常の汚染（Contamination）」への耐性

局所窓方式では、大きな異常の隣のピクセルを計算する際、その異常そのものが「背景辞書」の中に紛れ込んでしまうことが多々あります。

* **解決策**: 異常は通常、画像全体で見れば「稀な存在」です。クラスタリングを行うと、圧倒的多数を占める「正常な背景」が大きなクラスターを形成し、少数の異常はそれらのクラスターから外れるか、非常に小さな独立したグループになります。
* **メリット**: 正常なクラスターから得られた辞書を使って計算することで、 **「異常を使って異常を説明してしまう（見逃し）」** という自己消去現象を構造的に回避しやすくなります。


### クラスターベース辞書の運用フロー

1. **オフライン/事前学習**: 画像全体（または正常なサンプル群）をクラスタリングし、各クラスター  ごとに代表的な基底ベクトル（辞書 ）を構築します。
2. **クラスター割り当て**: 判定したいピクセル  が、どの  に最も近いかを判定します。
3. **再構成と判定**: 選ばれたクラスターの辞書  を用いて協調表現（CRDの計算）を行い、その誤差で異常を判定します。

## 仕組み

クラスターベース辞書（Cluster-based Dictionary）の仕組みは、 **「似た者同士をあらかじめグループ化しておき、そのグループの代表ルールで個々の画素をチェックする」** という、効率的かつ合理的なプロセスです。

__1. 構築フェーズ：背景の「カタログ」作り__

まず、画像全体（または正常な学習用画像）を分析して、その画像に存在する「背景の種類」を自動的に分類します。

- 特徴抽出: 各画素をベクトル（RGBやマルチスペクトル値）として扱います。
- クラスタリング（分類）: K-means などのアルゴリズムを使い、全画素を $K$ 個のクラスターに分けます（例：クラスター1=草、2=水、3=土）。
- サブ辞書の生成: 各クラスターに属する画素の中から、そのクラスターを代表するベクトルを抽出・選定し、各クラスター専用の辞書 $D_c$ を作成します。

__2. 検知フェーズ：代表ルールによる照合__

次に、異常かどうかを判定したいターゲット画素 $y$ を、先ほど作ったカタログと照らし合わせます。

1. クラスター選択: ターゲット画素 $y$ が、どのクラスターの重心に最も近いかを計算し、適用する辞書 $D_c$ を一瞬で決定します。ここがLRBとの違いです。LRBは毎回全候補から探しますが、クラスターベースは「君はクラスター2担当ね」と即決します。

2. 協調表現の計算: 選ばれた辞書 $D_c$ を使い、CRDと同じ数式で重み $\alpha$ を求めます。

$$\alpha = (D_c^T D_c + \lambda I)^{-1} D_c^T y$$

3. 異常スコアの算出:

$$Score = \|y - D_c \alpha\|_2$$

もしターゲットが「クラスター2（水）」に分類されたのに、実際には「油」の成分を含んでいれば、水の辞書 $D_c$ では再現しきれず、誤差（スコア）が大きくなります。

3. なぜこの仕組みが効くのか？（数学的メリット）

空間的制約からの解放: CRDのような「窓」は使いません。画像上の位置が離れていても、同じ「草」であれば同じ辞書で評価します。これにより、窓の中にたまたま異常が混入して辞書が汚染されるリスク（Dictionary Contamination）を大幅に減らせます。逆行列の使い回し: 同じクラスターに属する画素であれば、$(D_c^T D_c + \lambda I)^{-1}$ の部分は一度計算すればそのクラスターの全画素で使い回せます。これが、この手法が爆速である理由です。


__仕組みのイメージ__

- CRD/LRB: 「あなたの周りの数人に、あなたを説明してもらいなさい」
- クラスターベース: 「あなたはこのグループの一員ね。じゃあ、そのグループの代表メンバーの組み合わせで、あなたを再現できるか試すよ」


