CRD（協調表現）のように「周囲や画像全体の画素を辞書として使い、その組み合わせで説明できるか」を測る手法は、**「表現ベース（Representation-based）」**や**「再構成ベース（Reconstruction-based）」**の手法と呼ばれます。

CRDの弱点（計算量、L2ノルムの甘さ、窓サイズ依存）を補うために開発された、主な手法を紹介します。


### 1. SRD (Sparse Representation-based Detector)

CRDの「親」にあたる、より厳格な手法です。

* **原理**: 目的関数に **L1ノルム**（$\|\alpha\|_1$）を使用します。
* **特徴**: 辞書の中から「本当に似ている数個の画素」だけを選び出してターゲットを説明しようとします。
* **CRDとの違い**: CRDが辞書全体で「協調的」に説明するのに対し、SRDは「少数の精鋭」で説明します。
* **メリット**: 異常と背景の分離性能が非常に高いです。
* **デメリット**: L1ノルムの最適化計算（繰り返し計算）が必要なため、**CRDよりも圧倒的に計算が重い**です。


### 2. LRB (Local Representation-based Detector)

CRDの「辞書の選び方」を工夫した手法です。

* **原理**: 窓内の全ての画素を辞書にするのではなく、ターゲット $y$ にスペクトルが似ている上位 $K$ 個の画素だけを画像全域または窓内から選んで辞書を構成します。
* **メリット**: 境界（エッジ）部分で、異なる素材が辞書に混ざるのを防げます。
* **CRDとの違い**: CRDは「窓内すべて」を使いますが、LRBは「似た者同士」だけを集めた精選辞書を使います。


### 3. LRaSMD (Low-Rank and Sparse Matrix Decomposition)

「窓」という概念を捨て、行列演算の力で背景と異常を分離する手法です。

* **原理**: 画像行列 $X$ を、 **背景（低ランク行列 $L$）と異常（疎行列 $S$）** に分解します（$X = L + S$）。
* **特徴**: 画像全体で「繰り返し現れるパターン」を背景として辞書化し、そこから外れる「稀なパターン」を異常として抽出します。
* **メリット**: 窓サイズの設定が不要で、CRDが苦手とする「巨大な異常」も鮮明に分離できます。


### 4. GAD (Graph-based Anomaly Detector)

画素同士の「つながり（グラフ）」を辞書的な構造として利用します。

* **原理**: 各画素をノードとし、スペクトルが似ている画素同士をエッジで結んだグラフを作成します。
* **特徴**: グラフ理論に基づき、多数派の「大きな島（背景）」から孤立している「小さな島」を異常とみなします。
* **メリット**: 非線形な背景構造（複雑に混ざり合った地形など）に非常に強いです。


### 5. CNN-based Autoencoder (Deep Learning)

近年の主流で、深層学習による「ニューラルネットワークそのものを辞書にする」手法です。

* **原理**: 自己符号化器（Autoencoder）に正常な背景画像だけを学習させます。
* **特徴**: ネットワークの重み（Weight）が「背景のルールを記した辞書」になります。
* **メリット**: 複雑なテクスチャや模様があっても、人間がルールを定義することなく、高度な背景辞書を自動構築できます。



### 1. KLRX (Kernel Local RX)

LRXやCRDを**カーネル法**によって非線形化した手法です。

* **原理**: データを高次元の特徴空間（ヒルベルト空間）に写像してから、そこでマハラノビス距離や再構成誤差を計算します。
* **解決する弱点**: CRDやLRXは「線形（足し算・引き算）」の関係しか扱えませんが、KLRXは背景と異常が複雑に混ざり合っている（非線形な）場合でも、そのわずかな「法則性の違い」を捉えることができます。
* **イメージ**: 紙の上では重なっている2つのグループを、紙を折り曲げることで引き離して見分けるような仕組みです。

---

### 2. BACM (Background Anomaly Component Model)

「背景辞書」を作る際に、**「背景らしい成分」と「異常らしい成分」を同時に推定**する手法です。

* **原理**: CRDは「背景辞書だけで説明しよう」としますが、BACMは「ターゲット = 背景成分 + 異常成分」と仮定し、両方の成分を最適化によって同時に分離します。
* **解決する弱点**: 背景辞書に異常が混じってしまった場合（汚染）でも、最適化プロセスの中で「これは異常成分だ」と切り分けられるため、自己消去が起きにくくなります。
* **メリット**: 窓サイズの設定ミスに対して、従来のCRDよりも頑健（堅牢）です。

---

### 3. TV-Regularized Anomaly Detector (全変動正則化を用いた手法)

画像の**「滑らかさ」**を辞書の制約に組み込む手法です。

* **原理**: 異常検知の数式に「TV（Total Variation）正則化」を加えます。
* **特徴**: 背景は「空間的に滑らかに変化する」はずであり、異常は「局所的に急激に変化する」はずであるという空間情報を数学的に強制します。
* **解決する弱点**: スペクトル（色）が似ていても、空間的な「浮き出し方」が不自然なものを強調できるため、カモフラージュされた異常の検知に強いです。


### 手法の比較まとめ

| 手法名 | 辞書の中身 | 決定的なメリット |
| --- | --- | --- |
| **CRD** | 近所の画素全部 | 計算が（SRDより）速く、バランスが良い。 |
| **SRD** | 近所の画素（少数精鋭） | 検出精度が最も高いが、非常に重い。 |
| **LRB** | 似ている画素（上位K個） | 境界部分の誤検知に強い。 |
| **LRaSMD** | 全体の低ランク構造 | **巨大な異常**も検知可能。窓サイズ不要。 |
| **Autoencoder** | 学習済みモデルの重み | 人間の知識を超えた複雑な背景に対応。 |

### 次のステップへの提案

もし「CRDよりも精度を上げたいが、計算時間は抑えたい」ということであれば、**LRB** か、以前紹介した **クラスターベース辞書** が最も現実的な選択肢になります。



