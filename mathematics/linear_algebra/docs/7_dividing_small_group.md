## 小行列表記

行列を、より小さな「ブロック」の集まりとして扱う手法を **ブロック行列（行列の分割）** と呼びます。

巨大な行列をそのまま扱うのではなく、意味のある塊ごとに分割して表記することで、計算を簡略化したり、行列の構造を浮き彫りにしたりできる、非常に強力なテクニックです。

### 1. ブロック行列の表記法

行列 $A$ をいくつかの「小行列（Submatrix）」に切り分けます。例えば、以下のように4つのブロックに分けることができます。

$$A = \left( \begin{array}{cc|ccc}
a_{11} & a_{12} & a_{13} & a_{14} & a_{15} \\
a_{21} & a_{22} & a_{23} & a_{24} & a_{25} \\
\hline
a_{31} & a_{32} & a_{33} & a_{34} & a_{35} \\
a_{41} & a_{42} & a_{43} & a_{44} & a_{45}
\end{array} \right) 
= \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix}$$

ここで、$A_{11}$ や $A_{12}$は単なる数字ではなく、それ自体が **行列（小行列）** です。

### 2. ブロック行列の演算ルール

ブロック行列の素晴らしい点は、 **「ブロックをあたかも一つの数字（スカラー）のように扱って、通常の行列と同じルールで演算できる」** という点です。

#### ① 和（足し算）

分割の仕方が同じであれば、各ブロック同士を足すだけです。

$$\begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix} + \begin{pmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{pmatrix} = \begin{pmatrix} A_{11}+B_{11} & A_{12}+B_{12} \\ A_{21}+B_{21} & A_{22}+B_{22} \end{pmatrix}$$

#### ② 積（掛け算）

積の場合も、通常の「行×列」のルールが適用されます。ただし、各ブロックのサイズが掛け算可能な状態（左の列数＝右の行数）である必要があります。

$$\begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix} \begin{pmatrix} B_{11} \\ B_{21} \end{pmatrix} = \begin{pmatrix} A_{11}B_{11} + A_{12}B_{21} \\ A_{21}B_{11} + A_{22}B_{21} \end{pmatrix}$$

### 3. なぜブロックに分けるのか？（利便性）

小行列を用いることには、実務上の大きなメリットが3つあります。

#### A. 計算の並列化・高速化

巨大な行列（例：100万×100万）を一度に計算しようとすると、メモリが不足したり時間がかかりすぎたりします。ブロックに分ければ、**各ブロックを複数のCPUで並列に計算**し、最後に統合することができます。

#### B. 特殊な構造の発見

例えば、以下のような **「ブロック対角行列」** は、対角線上のブロック以外がすべて零行列です。

$$A = \begin{pmatrix} A_{11} & O \\ O & A_{22} \end{pmatrix}$$

この形であれば、行列式は $\det(A) = \det(A_{11}) \cdot \det(A_{22})$、逆行列は $A^{-1} = \begin{pmatrix} A_{11}^{-1} & O \\ O & A_{22}^{-1} \end{pmatrix}$ となり、**計算コストが劇的に下がります。**

#### C. データの意味的な整理

データ分析において、「ユーザー属性のデータ」と「行動履歴のデータ」が一つの行列に入っている場合、それらを別々のブロック（$A_{attr}, A_{hist}$）として管理することで、数式がデータの意味を反映した分かりやすいものになります。


### 4. 応用：シューア補行列（Schur Complement）

ブロック行列を用いた最も重要な公式の一つに、逆行列を計算するための手法があります。

$$A = \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix}$$

この行列の逆行列を求める際、ブロック同士を組み合わせた特定の式を用いることで、より小さなサイズの行列の逆行列計算に帰着させることができます。これは統計学の「条件付き分散」や、制御理論などで多用されます。


__例題__

行列を、小行列に分割した状態で、元の行列の積と、分割した行列の積が一致することをPythonを使って確認するコードを作ってみます。

- コードは、与えられた行列で偶然一致したということがないように要素はランダムに変化するようにします。
- 一致することの確認はnumpyの関数でallclose()という関数を用いて確認します。

```python
import numpy as np
import matplotlib.pyplot as plt

# 1. 元の行列 (4x4) を作成
np.random.seed(42)
A = np.random.randint(1, 10, (4, 4))
B = np.random.randint(1, 10, (4, 4))

# 2. 通常の行列積を計算
C_full = A @ B

# 3. 小行列（ブロック）に分割 (2x2 ずつ)
# A = [[A11, A12], [A21, A22]]
A11, A12 = A[:2, :2], A[:2, 2:]
A21, A22 = A[2:, :2], A[2:, 2:]

# B = [[B11, B12], [B21, B22]]
B11, B12 = B[:2, :2], B[:2, 2:]
B21, B22 = B[2:, :2], B[2:, 2:]

# 4. ブロック行列の積の公式に従って計算
# C11 = A11*B11 + A12*B21
C11 = A11 @ B11 + A12 @ B21
C12 = A11 @ B12 + A12 @ B22
C21 = A21 @ B11 + A22 @ B21
C22 = A21 @ B12 + A22 @ B22

# 5. ブロックを結合して一つの行列に戻す
C_block = np.block([[C11, C12], [C21, C22]])

# 6. 一致の確認
print("Original Matrix Multiplication Result:\n", C_full)
print("\nBlock Matrix Multiplication Result:\n", C_block)
print("\nAre they equal?", np.allclose(C_full, C_block))
```

__結果__

実行結果は何度やっても np.allclose(C_full, C_block) が `True` となるはずです。

__1. 数学的な整合性の証明__

このコードは、行列積の定義が**再帰的な構造**（自己相似性）を持っていることを実証しています。

* **演算の保存:** 大きな行列  を一気に計算した結果（`C_full`）と、断片的な  の積を組み合わせて作った結果（`C_block`）が `np.allclose` で `True` になることは、 **「行列の積の定義は分割しても壊れない」** ことを意味します。
* **分配法則の適用:** ブロック計算の式（例：）は、行列積の基本である「左の行ベクトルと右の列ベクトルの内積」を、単に「塊ごと」に実行しているに過ぎないことがわかります。

__2. アルゴリズム的・計算機的な分析__

このコードの手法（ブロック分割）は、現代のコンピューティングにおいて極めて重要です。

* **キャッシュ効率の最適化:** コンピュータのメモリ（RAM）は、巨大な行列を一度に扱うよりも、CPUに近い高速な「キャッシュメモリ」に収まるサイズの小行列（ブロック）に分割して計算する方が、データの転送待ちが発生せず、圧倒的に高速になります。
* **並列計算の可能性:**
コード内の `C11, C12, C21, C22` の計算には、お互いの計算結果が必要ありません。これは、 **「4つのCPUコアがあれば、通常の4倍速で計算を終わらせられる」** という並列化のポテンシャルを可視化しています。


__3. 実務的な価値と応用__

この検証結果は、単なるパズルではなく、以下のような高度な技術の基礎となっています。

__A. 分割統治法の代表例（ストラッセンのアルゴリズム）__

このコードは「ブロックごとに計算しても結果が同じ」ことを示しましたが、実は数学的にはこのブロック計算の回数を減らす工夫（ストラッセン法）が存在します。これにより、行列が巨大になればなるほど、通常の掛け算よりも高速に計算が可能になります。

__B. GPUコンピューティング（CUDAなど）__

ディープラーニングなどで使われるGPUは、数千個の小さなコアを持っています。GPU内部では、まさにこのコードのように巨大な行列（重み）を小さなブロックに分割し、各コアが同時並行で小行列の積を計算することで、超高速な推論を実現しています。

__分析のまとめ__

このコードは、 **「行列を『数字の集合』ではなく『情報のユニット（ブロック）』として扱うことができる」** という線形代数の柔軟性を証明しています。

1. **一貫性:** どのサイズで切っても、積のルールは不変。
2. **拡張性:** 大規模なデータは小分けにして処理できる。
3. **堅牢性:** `np.allclose`（浮動小数点誤差を考慮した比較）を使うことで、コンピュータ上での計算精度も確認されている。



